{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load packages; may take a few seconds to run.\n",
    "using Gen\n",
    "using PyPlot\n",
    "using StatsBase\n",
    "using Statistics\n",
    "import Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "second(x) = x[2] #used to pull logweight from tuple of (trace, logweight)\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text to introduce AIDE here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Compare the distribution of return values of two generative functions, using AIDE\n",
    "# Returns an unbiased estimate of an upper bound on the symmetrized KL divergence\n",
    "#    between f and g.\n",
    "function AIDE_compare(\n",
    "        f, g, #generative functions to compare. \n",
    "            #Both should return the (comparable) \"output\" value of interest.\n",
    "        \n",
    "        input, #any input to generative functions; must be same for both of them.\n",
    "        \n",
    "        ret_to_f, ret_to_g, #Functions. Input: return value (from f or g)\n",
    "                                #Output: constraints for one generative, \n",
    "                                #sufficient to guarantee same return value\n",
    "        \n",
    "        Nf, Ng, #Number of traces to draw from each generative\n",
    "        Mf, Mg  #Number of runs of each to use to estimate a given generative's score of a trace\n",
    "    )\n",
    "    cm = choicemap()\n",
    "    f_vals = [Gen.get_retval(generate(f, input, cm)[1]) for i in 1:Nf]\n",
    "    g_vals = [Gen.get_retval(generate(g, input, cm)[1]) for i in 1:Ng]\n",
    "    \n",
    "    f_scores_of_g = [mean([second(generate(f, input, ret_to_f(v))) for j in 1:Mf]) \n",
    "                        for v in g_vals] #One average log density from f for each draw of g\n",
    "    g_scores_of_f = [mean([second(generate(g, input, ret_to_g(v))) for j in 1:Mf])\n",
    "                        for v in f_vals] #(as above)  Note that we're ignoring stdev of the...\n",
    "    f_scores_of_f = [mean([second(generate(f, input, ret_to_f(v))) for j in 1:Mf]) \n",
    "                        for v in f_vals] #(as above)  ...score estimation process, because...\n",
    "    g_scores_of_g = [mean([second(generate(g, input, ret_to_g(v))) for j in 1:Mf]) \n",
    "                        for v in g_vals] #(as above)  ...it's more hassle than it's worth.\n",
    "    \n",
    "    KLfg = mean(f_scores_of_f) - mean(g_scores_of_f)\n",
    "    KLgf = mean(g_scores_of_g) - mean(f_scores_of_g)\n",
    "    \n",
    "    symse2 = (var(f_scores_of_f .- g_scores_of_f; corrected=true)/Nf +  #squared standard error\n",
    "                var(g_scores_of_g .- f_scores_of_g; corrected=true)/Ng) #(using paired samples)\n",
    "    \n",
    "    (KLfg + KLgf, sqrt(symse2)) #tuple of (symmetrized KL hat, standard error thereof)\n",
    "end\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"Coinflip\" example\n",
    "\n",
    "Say we're inferring the parameter of a Bernoulli distribution — the \"weightedness\" of a \"coinflip\" — based on a certain number of observations of the outcome. To do Bayesian inference, we need a prior on the parameter $p$; let's say it's distributed uniformly from 0 to 1. Conveniently, the uniform distribution is a special case of the beta distribution — $Beta(1,1)$ — so we can use the following generative model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@gen function binom_prior(α, β)\n",
    "    p ~ beta(α, β)\n",
    "    p\n",
    "end\n",
    "\n",
    "@gen function basic_binom(n, α, β)\n",
    "    p = @trace(binom_prior(α, β))\n",
    "    h ~ binom(n, p)\n",
    "    h\n",
    "end\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do inference over this model, we might use importance sampling. In order to be able to use AIDE to evaluate the quality of that inference, we need the inference procedure itself to be a generative function (that returns one sample from the approximate posterior), as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "function importance_cond_binom_for(samps) #A factory which constructs an \n",
    "                #inference function that uses a given number of samples\n",
    "    @gen function i_c_b(h, #number of \"heads\" observed\n",
    "            n, #number of \"coinflips\"\n",
    "            α = 1., β = 1.)\n",
    "        constraint = choicemap((:h, h))\n",
    "        logweights = Vector{Float64}(undef, samps)\n",
    "        ps = Vector{Float64}(undef, samps)\n",
    "        for s in 1:samps\n",
    "            p = @trace(binom_prior(α, β),:data => s)\n",
    "            constraint[:p] = p\n",
    "            ps[s] = p\n",
    "            (_, logweights[s]) = generate(basic_binom, (n, α, β), constraint)\n",
    "                    #in this simple case, this is just a more-complicated way of calling\n",
    "                        #Distributions.Binomial(...).logpdf. However, this pattern generalizes\n",
    "                        #better to inference over arbitrary generative functions.\n",
    "        end\n",
    "        logweights .-= max(logweights...)\n",
    "        weights = exp.(logweights)\n",
    "        weights ./= sum(weights)\n",
    "        whichOne ~ categorical(weights)\n",
    "        p = ps[whichOne]\n",
    "        p\n",
    "    end\n",
    "end\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test that out for 0 heads out of 10 coinflips, using just 5 samples from the prior. Note that we'd intuitively expect most of the posterior to be below 0.1, but with few samples to do importance sampling over, inference appears poor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20308731980110925"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Random.seed!(0)\n",
    "\n",
    "importance_cond_binom_for(5)(0,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm... let's graph the output for 7 heads out of 10, using different numbers of samples for importance sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "Figure(PyObject <Figure size 640x480 with 1 Axes>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hist([importance_cond_binom_for(1)(7,10) for i in 1:10000], color=\"b\", alpha =.5)\n",
    "hist([importance_cond_binom_for(3)(7,10) for i in 1:10000], color=\"g\", alpha =.5)\n",
    "hist([importance_cond_binom_for(20)(7,10) for i in 1:10000], color=\"r\", alpha =.5)\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need a gold standard to compare the above inference against. Luckily, because beta and binomial are conjugate distributions, there's an analytic solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "@gen function analytic_cond_binom(h, n, α = 1., β = 1.)\n",
    "    p ~ beta(α + h, β + n - h)\n",
    "    p\n",
    "end\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we need functions to convert the output (of either generative inference function) to a constraint on each of those functions that's sufficient to guarantee that output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "function ret_to_importance_constraint(p)\n",
    "    constraint = choicemap((:whichOne, 1))\n",
    "    constraint[:data => 1 => :p] = p\n",
    "    constraint\n",
    "end\n",
    "\n",
    "function ret_to_analytic_constraint(p)\n",
    "    choicemap((:p, p))\n",
    "end\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, let's put it all together. Using only a very small number of samples from each generative inference function, let's quickly compare how our estimated KL bound improves as we increase the number of prior samples for the importance sampling method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-element Array{Tuple{Float64,Float64},1}:\n",
       " (2.181169155644955, 1.3884452559069211)\n",
       " (0.735265026766756, 0.9473137936958114)\n",
       " (0.08342677373663299, 0.23139900531179888)\n",
       " (-0.10586311583214392, 0.10424573505094893)\n",
       " (0.07388414969032553, 0.17965617147700239)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Random.seed!(4)\n",
    "\n",
    "(h,n) = (7,10)\n",
    "\n",
    "ns = 5\n",
    "ms = 5\n",
    "\n",
    "[AIDE_compare(importance_cond_binom_for(i), analytic_cond_binom, #generative functions to compare. Should return the important value.\n",
    "        (h,n), #any input to generative functions; must be same for both\n",
    "        ret_to_importance_constraint, ret_to_analytic_constraint, #take a return value from either generative, and produce constraints for one generative\n",
    "        ns, ns, #Number of traces to draw from each\n",
    "        ms, ms  #Number of runs of each to use to estimate score\n",
    "    ) for i in 1:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that while AIDE's estimated KL (the first element of the tuples) is in expectation an upper bound on KL and thus should be above 0, it's still a stochastic algorithm, and so below zero is possible, as seen above.\n",
    "\n",
    "Now we've seen that it works, let's do a slightly more computationally-intensive run and turn it into a graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "ns = 400\n",
    "ms = 30\n",
    "\n",
    "results = [AIDE_compare(importance_cond_binom_for(i), analytic_cond_binom, #generative functions to compare. Should return the important value.\n",
    "        (h,n), #any input to generative functions; must be same for both\n",
    "        ret_to_importance_constraint, ret_to_analytic_constraint, #take a return value from either generative, and produce constraints for one generative\n",
    "        ns, ns, #Number of traces to draw from each\n",
    "        ms, ms  #Number of runs of each to use to estimate score\n",
    "    ) for i in 1:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "jl:light,ipynb"
  },
  "kernelspec": {
   "display_name": "Julia 1.4.0",
   "language": "julia",
   "name": "julia-1.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
