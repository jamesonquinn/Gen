{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42"
     ]
    }
   ],
   "source": [
    "print(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Gen\n",
    "using GenViz\n",
    "using Statistics\n",
    "include(\"DistributionsBacked.jl\")\n",
    "#include(\"DistributionsForwardBacked.jl\")\n",
    "using PyPlot\n",
    "using AdvancedHMC\n",
    "using Distributions\n",
    "#using ForwardDiff #we'll replace ForwardDiff with Zygote later; for now, follow working model code\n",
    "using Zygote\n",
    "\n",
    "const my_normal = DistributionsBacked{Float64}((mu, sigma) -> \n",
    "                            Distributions.Normal(mu, sigma), [true, true], true)\n",
    "const my_unif = DistributionsBacked{Float64}((lo, hi) -> \n",
    "                            Distributions.Uniform(lo, hi), [true, true], true)\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@gen function corbiv_model() #correlated bivariate normal\n",
    "    ρ ~ my_unif(-1., 1.)\n",
    "    x ~ my_normal(0., 1.)\n",
    "    y ~ my_normal(ρ*x, sqrt(1. - ρ^2))\n",
    "end\n",
    "\n",
    "@gen function cormiv_model() #correlated bivariate normal\n",
    "    ρ ~ my_unif(0., 1.) #correlation between x and y\n",
    "    ρ2 ~ my_unif(0., ρ) #correlation between z and (x or y) \n",
    "    zy_cond_zx = (1-ρ2^2)*ρ2\n",
    "    x ~ my_normal(0., 1.)\n",
    "    y ~ my_normal(ρ*x, sqrt(1. - ρ^2))\n",
    "    z ~ my_normal(ρ2*x + zy_cond_zx*y, sqrt(1. - ρ2^2 - zy_cond_zx^2))\n",
    "end\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "function constrainρ(ρ::Float64)\n",
    "    constraints = Gen.choicemap()\n",
    "    constraints[:ρ] = ρ\n",
    "    constraints\n",
    "end\n",
    "\n",
    "function constrainρ2(ρ::Float64, ρ2, z)\n",
    "    constraints = Gen.choicemap()\n",
    "    constraints[:ρ] = ρ\n",
    "    constraints[:ρ2] = ρ2\n",
    "    constraints[:z] = z\n",
    "    \n",
    "    \n",
    "    constraints\n",
    "end\n",
    "\n",
    "function mcmc_inference(ρ, num_iters, update, selection)\n",
    "    observation = constrainρ(ρ)\n",
    "    (trace, _) = generate(corbiv_model, (), observation)\n",
    "    samples = Array{Float64}(undef,num_iters,2)\n",
    "    for i=1:num_iters\n",
    "        trace = update(trace, selection)\n",
    "        ch = get_choices(trace)\n",
    "        samples[i,1] = ch[:x]\n",
    "        samples[i,2] = ch[:y]\n",
    "    end\n",
    "    samples\n",
    "end\n",
    "\n",
    "function mcmc_m_inference(ρ, ρ2, z, num_iters, update)\n",
    "    observation = constrainρ2(ρ, ρ2, z)\n",
    "    (trace, _) = generate(cormiv_model, (), observation)\n",
    "    samples = Array{Float64}(undef,num_iters,2)\n",
    "    for i=1:num_iters\n",
    "        trace = update(trace)\n",
    "        ch = get_choices(trace)\n",
    "        samples[i,1] = ch[:x]\n",
    "        samples[i,2] = ch[:y]\n",
    "    end\n",
    "    samples\n",
    "end\n",
    "\n",
    "function block_mh(tr, selection)\n",
    "    (tr, _) = mh(tr, select(:x, :y))\n",
    "    tr\n",
    "end\n",
    "\n",
    "\n",
    "function simple_hmc(tr, selection)\n",
    "    (tr, _) = hmc(tr, select(:x, :y))\n",
    "    tr\n",
    "end\n",
    "\n",
    "\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5×2 Array{Float64,2}:\n",
       " -1.35263    -0.442157\n",
       " -0.162897    0.27729\n",
       " -1.45835     0.78756\n",
       " -0.677165    0.809327\n",
       "  0.0927347   0.137221"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iters = 10_000\n",
    "show = 5\n",
    "ρ = -.5\n",
    "samps = mcmc_inference(ρ, iters, block_mh, select(:x,:y))\n",
    "samps[(iters-show+1):iters,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5×2 Array{Float64,2}:\n",
       " -0.323401  -0.406428\n",
       " -1.0715    -0.966912\n",
       " -1.67169   -1.8933\n",
       " -2.48853   -2.76503\n",
       " -3.38674   -3.63997"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iters = 100\n",
    "show = 5\n",
    "ρ = .8\n",
    "samps = mcmc_inference(ρ, iters, simple_hmc)\n",
    "samps[(iters-show+1):iters,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.023045384441693968\n",
      "0.8589097159669802\n"
     ]
    }
   ],
   "source": [
    "println(mean(samps))\n",
    "println(cor(samps[:,1],samps[:,2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Disable AdvancedHMC's NUTS logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ActiveFilteredLogger{Base.CoreLogging.SimpleLogger,typeof(ignore_sampling_filter)}(ignore_sampling_filter, Base.CoreLogging.SimpleLogger(IJulia.IJuliaStdio{Base.PipeEndpoint}(IOContext(Base.PipeEndpoint(RawFD(0x00000031) open, 0 bytes waiting))), Info, Dict{Any,Int64}()))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Logging\n",
    "using LoggingExtras\n",
    "\n",
    "function ignore_sampling_filter(log_args)\n",
    "    !(occursin(\"sampling steps\",log_args.message) || occursin(\"adapation steps\",log_args.message))\n",
    "end\n",
    "logger = ActiveFilteredLogger(ignore_sampling_filter, global_logger())\n",
    "\n",
    "\n",
    "if !(@isdefined old_logger) #do this only once\n",
    "    old_logger = global_logger(logger)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "my_nuts (generic function with 2 methods)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric = DiagEuclideanMetric(2) #In principle, this could be \"pre-tuned\". In practice, why??\n",
    "n_NUTS_steps = 2\n",
    "n_adapts = 1\n",
    "initial_ϵ_reduce_fac = 10\n",
    "\n",
    "function my_nuts(trace, selection)\n",
    "    filtered_choices = get_selected(get_choices(trace), selection)\n",
    "    cur_xy = to_array(filtered_choices, Float64)\n",
    "    \n",
    "    retval_grad = nothing #accepts_output_grad(get_gen_fn(trace)) ? zero(get_retval(trace)) : nothing\n",
    "    \n",
    "    function update_xy(val)\n",
    "        extra_constraints = from_array(filtered_choices, val)\n",
    "        update(trace, (), (NoChange(),), extra_constraints)\n",
    "    end\n",
    "    \n",
    "    function val_to_lp_plus_c(val)\n",
    "        (new_trace, weight, discard, retdiff) = update_xy(val)\n",
    "        weight\n",
    "    end\n",
    "    \n",
    "    function val_to_grad(val)\n",
    "        (new_trace, weight, discard, retdiff) = update_xy(val)\n",
    "        (retval_grad_out, values_trie, gradient_trie) = choice_gradients(new_trace, selection, retval_grad)\n",
    "        grad = [gradient_trie[:x], gradient_trie[:y]]\n",
    "        (weight, grad)\n",
    "    end\n",
    "    \n",
    "    # Define a Hamiltonian system, using metric defined globally above\n",
    "    hamiltonian = Hamiltonian(metric, val_to_lp_plus_c, val_to_grad)\n",
    "    \n",
    "    # Define a leapfrog solver, with initial step size chosen heuristically\n",
    "    initial_ϵ = find_good_stepsize(hamiltonian, cur_xy) ./ initial_ϵ_reduce_fac\n",
    "    integrator = Leapfrog(initial_ϵ)\n",
    "    \n",
    "    # Define an HMC sampler, with the following components\n",
    "    #   - multinomial sampling scheme,\n",
    "    #   - generalised No-U-Turn criteria, and\n",
    "    #   - windowed adaption for step-size and diagonal mass matrix\n",
    "    proposal = NUTS{MultinomialTS, GeneralisedNoUTurn}(integrator)\n",
    "    adaptor = StanHMCAdaptor(MassMatrixAdaptor(metric), StepSizeAdaptor(0.8, integrator))\n",
    "\n",
    "    # Run the sampler to draw samples from the specified Gaussian, where\n",
    "    #   - `samples` will store the samples\n",
    "    #   - `stats` will store diagnostic statistics for each sample\n",
    "    \n",
    "    samples, stats = sample(hamiltonian, proposal, cur_xy, n_NUTS_steps, adaptor, n_adapts; progress=false)\n",
    "    \n",
    "    #println(samples[3])\n",
    "    \n",
    "    \n",
    "    (new_trace, weight, discard, retdiff) = update_xy(samples[n_NUTS_steps])\n",
    "    new_trace\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5×2 Array{Float64,2}:\n",
       " -0.382167  -0.255266\n",
       " -0.39219   -0.231565\n",
       " -0.430805  -0.415158\n",
       " -0.211551  -0.28566\n",
       " -1.05492   -1.11842"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iters = 200\n",
    "show = 5\n",
    "ρ = .99\n",
    "\n",
    "\n",
    "samps = mcmc_inference(ρ, iters, my_nuts)\n",
    "samps[(iters-show+1):iters,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7798542303923484"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cor(samps[1:iters-1,1],samps[2:iters,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base.CoreLogging.LogLevelDebug"
     ]
    }
   ],
   "source": [
    "using Logging\n",
    "\n",
    "print(LogLevel)\n",
    "print(Logging.Debug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "jl:light,ipynb"
  },
  "kernelspec": {
   "display_name": "Julia 1.4.0",
   "language": "julia",
   "name": "julia-1.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
